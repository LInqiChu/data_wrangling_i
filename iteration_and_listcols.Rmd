---
title: "iteration_and_listcols"
output: html_document
date: "2025-10-28"
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)


```


## Make a list

```{r}
l = list(
  vec_numeric = 1:23,
  char_vec = c("Jeff"),
  mat = matrix(1:8, nrow = 2, ncol = 4),
  vec_logical = c(TRUE, FALSE),
  summary = summary(rnorm(1000), mean = 4))

l
l[[1]]
l[["vec_numeric"]]
l$mat


```

## Loops

```{r}
list_norms = 
  list(
    a = rnorm(20, 3, 1),
    b = rnorm(20, 0, 5),
    c = rnorm(20, 10, .2),
    d = rnorm(20, -3, 1)
  )

is.list(list_norms)

```


use the function

```{r}
mean_and_sd = function(x) {
  
  if (!is.numeric(x)) {
    stop("Argument x should be numeric")
  } else if (length(x) == 1) {
    stop("Cannot be computed for length 1 vectors")
  }
  
  mean_x = mean(x)
  sd_x = sd(x)

  tibble(
    mean = mean_x, 
    sd = sd_x
  )
}
```

```{r}
mean_and_sd(list_norms[[1]])
mean_and_sd(list_norms[[2]])
mean_and_sd(list_norms[[3]])
mean_and_sd(list_norms[[4]])
```


use a loop to iterate!

```{r}
output = vector("list", length = 4)

for (i in 1:4){
  
  output[[i]] = mean_and_sd(list_norms[[i]])
}


output

```

use 'map' to do the same thing

```{r}
output = map(list_norms, mean_and_sd)

output = map(list_norms, median)
```


Check out some 'map' variants

```{r}
map_dfr(list_norms, mean_and_sd, .id = "sample")

map_dbl(list_norms, median)
```


# List columns

try to put my list into a dataframe!!

```{r}
listcol_df = 
  tibble(
    name = c("a","b","c","d"),
    sample = list_norms
  )
```


Did this really work?

```{r}
pull(listcol_df, name)
pull(listcol_df, sample)
```

can I apply 'mean_and_df'?

```{r}
mean_and_sd(pull(listcol_df, sample)[[1]])
```

iterate using 'map'

```{r}
map(pull(listcol_df, sample), mean_and_sd)
```

adding a column

```{r}
listcol_df =
  listcol_df |>
  mutate(
    summary = map(sample, mean_and_sd)
  )

pull(listcol_df, summary)
```

```{r}
listcol_df |>
  select(-sample) |>
  unnest(summary) # 展开summary列
```

## Revisit NSDUH

```{r}
nsduh_url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

nsduh_html = read_html(nsduh_url)

nsduh_import = function(html, table_num){
  data = 
  html |> 
  html_table() |> 
  nth(table_num) |>
  slice(-1) |> 
  select(-contains("P Value")) |>
  pivot_longer(
    -State,
    names_to = "age_year", 
    values_to = "percent") |>
  separate(age_year, into = c("age", "year"), sep = "\\(") |>
  mutate(
    year = str_replace(year, "\\)", ""),
    percent = str_replace(percent, "[a-c]$", ""),
    percent = as.numeric(percent)) |>
  filter(!(State %in% c("Total U.S.", "Northeast", "Midwest", "South", "West")))
}

nsduh_import(nsduh_html, table_num = 1)
nsduh_import(nsduh_html, table_num = 2)
```


Try this with a 'for' loop

```{r}
output = vector("list", length = 3)

for (i in 1:3){
  output[[i]] = nsduh_import(nsduh_html, i)
  
}

```

Do this with 'map'

```{r}
map(1:3, nsduh_import, html = nsduh_html)
```

Do this all in a dataframe

```{r}
nsduh_df = 
  tibble(
    name = c("marj year","marj month","marj first"),
    number = 1:3
  ) |>
  mutate(
    table = map(number, nsduh_import, html = nsduh_html)
    ) |>
  unnest(table)

```

## Look at weather data

```{r}
library(p8105.datasets)
data("weather_df")
```

```{r}
weather_df |>
  filter(name == "CentralPark_NY") |>
  ggplot(aes(x = tmin, y = tmax)) +
  geom_point()

```
Let's do a regression

```{r}
weather_df |>
  filter(name == "CentralPark_NY") |>
  lm(tmax~ tmin, data = _)
```
Let's iterate differently

```{r}
weather_nest =
  weather_df |>
  nest(data = date:tmin)

```

```{r}
lm(tmax~tmin, data = pull(weather_nest,data)[[1]])
```
Do this using 'map'

```{r}
weather_lm = function(df){
  lm(tmax ~ tmin, data = df)
}
```

```{r}
map(pull(weather_nest, data), weather_lm)
```

```{r}
weather_nest |>
  mutate(
    lm_fits = map(data, weather_lm)
  )
```




